{"date": "20250820-164448", "endpoint_type": "openai", "label": null, "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct", "tokenizer_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct", "num_prompts": 16, "request_rate": 10000.0, "burstiness": 1.0, "max_concurrency": null, "duration": 20.28108626208268, "completed": 11, "total_input_tokens": 87940, "total_output_tokens": 11000, "request_throughput": 0.5423772601650776, "request_goodput": null, "output_throughput": 542.3772601650776, "total_token_throughput": 4878.436920066616, "mean_ttft_ms": 101.88099185258827, "median_ttft_ms": 100.93459999188781, "std_ttft_ms": 20.97608512591435, "p99_ttft_ms": 121.06506521813571, "mean_tpot_ms": 20.17890777745167, "median_tpot_ms": 20.17822563652885, "std_tpot_ms": 0.005936361833742061, "p99_tpot_ms": 20.194928064705568, "mean_itl_ms": 20.178907953605457, "median_itl_ms": 20.112531958147883, "std_itl_ms": 0.32793388583611865, "p99_itl_ms": 20.839407779276375}
{"date": "20250820-164628", "endpoint_type": "openai", "label": null, "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct", "tokenizer_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct", "num_prompts": 32, "request_rate": 10000.0, "burstiness": 1.0, "max_concurrency": null, "duration": 23.053896243916824, "completed": 19, "total_input_tokens": 151932, "total_output_tokens": 19000, "request_throughput": 0.8241557001460647, "request_goodput": null, "output_throughput": 824.1557001460646, "total_token_throughput": 7414.451691440375, "mean_ttft_ms": 750.826697232888, "median_ttft_ms": 425.5112069658935, "std_ttft_ms": 660.7813803535932, "p99_ttft_ms": 1930.7655618106946, "mean_tpot_ms": 22.239416287760044, "median_tpot_ms": 22.552131290395593, "std_tpot_ms": 0.6195827029205464, "p99_tpot_ms": 22.860493125455516, "mean_itl_ms": 22.239416496082196, "median_itl_ms": 20.946339005604386, "std_itl_ms": 18.264164348474097, "p99_itl_ms": 22.386107221245766}
{"date": "20250821-145057", "endpoint_type": "openai", "label": null, "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct", "tokenizer_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct", "num_prompts": 16, "request_rate": 10000.0, "burstiness": 1.0, "max_concurrency": null, "duration": 24.870429422706366, "completed": 16, "total_input_tokens": 127935, "total_output_tokens": 16000, "request_throughput": 0.6433342878025345, "request_goodput": null, "output_throughput": 643.3342878025345, "total_token_throughput": 5787.395044678613, "mean_ttft_ms": 2424.1501410724595, "median_ttft_ms": 2434.0063678100705, "std_ttft_ms": 1461.9616430572316, "p99_ttft_ms": 4696.326933242381, "mean_tpot_ms": 22.329813905980426, "median_tpot_ms": 22.325168263998712, "std_tpot_ms": 1.3752030373139028, "p99_tpot_ms": 24.522496424000096, "mean_itl_ms": 22.329814106881344, "median_itl_ms": 20.105124451220036, "std_itl_ms": 24.968965016479807, "p99_itl_ms": 21.50713238865137}